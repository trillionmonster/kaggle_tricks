{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Classify the presence and correct placement of tubes on chest x-rays to save lives\n\nNote: This notebook is still in progress.\nAny suggestions are welcome.\n\n***Please don't forget to upvote, if you find this helpful.***"},{"metadata":{},"cell_type":"markdown","source":"## TODO\n\n* Improve readibility\n    * Introductory Write-ups\n    * More comments\n* Image preprocessing\n    * Current architecture requires 3 channel inputs, need to fix it.\n    * Image preprocessing to improve the clarity of images\n    * More augmentation\n    * Different image sizes\n* Class balancing\n    * Weighted Loss Functions\n    * Oversampling\n* Architecture tuning\n* Ensembling"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"! pip install -q efficientnet >> /dev/null","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import modules"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\n\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '/kaggle/input/ranzcr-clip-catheter-line-classification'\n\nMODEL_PATH = '/kaggle/working/models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = 'TPU' # ['CPU' GPU' 'TPU']\n\nENABLE_MIXED_PRECISION = True # [True False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nFOLDS = 5 \n\nIMG_SIZE = 512\n\nBATCH_SIZE = 64 # [8, 16, 32, 64, 128, 256, 512]\n\nEPOCHS = 25\n\nEFF_NET = 'B4' # ['B0',B1','B2',B3','B4',B5','B6',B7']\n\nVERBOSE = 2 # [0: silent, 1: progress bar, 2: single line]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TF_RECS = len(os.listdir(f'{DATA_PATH}/train_tfrecords'))\n\nprint(NUM_TF_RECS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup devices and settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For kaggle tpus\nfrom kaggle_datasets import KaggleDatasets\nif DEVICE == 'TPU':\n    DATA_PATH = KaggleDatasets().get_gcs_path(DATA_PATH.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DEVICE == 'CPU':\n\n    strategy = tf.distribute.get_strategy()\n    print('\\nUsing Default Distribution Strategy  for CPU')\n\n\nif DEVICE == 'GPU':\n\n    gpu_accelerarors = tf.config.list_physical_devices('GPU')\n        \n    if len(gpu_accelerarors) > 1:\n        strategy = tf.distribute.MirroredStrategy()\n        print(f'Number of GPUs available: {len(gpu_accelerarors)}')\n        print('\\n Using Mirrored Distribution Strategy')\n        \n    else:\n        strategy = tf.distribute.get_strategy()\n        if len(gpu_accelerarors) == 1:\n            print(f'Number of GPUs available: 1')\n            print('\\nUsing Default Distribution Strategy for GPU')\n        else:\n            print('ERROR: GPU not available')\n            print('\\nUsing Default Distribution Strategy  for CPU')\n        \nif DEVICE == 'TPU':\n\n    try:\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(resolver)\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n        tpu_accelerarors = tf.config.list_logical_devices('TPU')\n        print(f'Number of TPU cores available: {len(tpu_accelerarors)}')\n        print(f'\\nUsing TPU Distribution Strategy')\n        \n    except:\n        print('ERROR: TPU not available')\n        print('\\nUsing Default Distribution Strategy for CPU')\n        strategy = tf.distribute.get_strategy()\n        \n        \nif ENABLE_MIXED_PRECISION:\n    \n    print('\\nMixed Precision enabled:')\n    \n    if DEVICE == 'GPU':\n        policy = mixed_precision.Policy('mixed_float16')\n        \n    if DEVICE == 'TPU':\n        policy = mixed_precision.Policy('mixed_bfloat16')\n        \n    mixed_precision.set_policy(policy)\n    \n    print('\\t...Compute dtype: %s' % policy.compute_dtype)\n    print('\\t...Variable dtype: %s' % policy.variable_dtype)\n\n\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'\\nREPLICAS: {REPLICAS}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset:\n    \n    feature_description = {\n        \"StudyInstanceUID\"           : tf.io.FixedLenFeature([], tf.string),\n        \"image\"                      : tf.io.FixedLenFeature([], tf.string),\n        \"ETT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Incompletely Imaged\"  : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"Swan Ganz Catheter Present\" : tf.io.FixedLenFeature([], tf.int64),\n    }\n    \n    def __init__(self, image_size):\n        self.image_size = image_size\n        \n    def parse_function(self, example_proto):\n        example = tf.io.parse_single_example(example_proto, self.feature_description)\n        image = tf.io.decode_image(example['image'], channels=3)\n        label = [example['ETT - Abnormal'],\n                 example['ETT - Borderline'],\n                 example['ETT - Normal'],\n                 example['NGT - Abnormal'],\n                 example['NGT - Borderline'],\n                 example['NGT - Incompletely Imaged'],\n                 example['NGT - Normal'],\n                 example['CVC - Abnormal'],\n                 example['CVC - Borderline'],\n                 example['CVC - Normal'],\n                 example['Swan Ganz Catheter Present']]\n        return image, label \n    \n    def augment_function(self, image, label):\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        image = tf.image.random_contrast(image, 0.8, 1.2)\n        image = tf.image.random_brightness(image, 0.1)   \n        return image, label \n    \n    def process_function(self, image, label):\n        image.set_shape([None, self.image_size, self.image_size, 3])\n        label.set_shape([None, 11])\n        image = tf.image.resize(image, [self.image_size, self.image_size], 'bilinear')/255\n        return image, label\n            \n    def generator(self, files, batch_size=1, repeat=False, augment=False, shuffle=True):\n        AUTO = tf.data.experimental.AUTOTUNE\n        ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n        if shuffle: \n            opt = tf.data.Options()\n            opt.experimental_deterministic = False\n            ds = ds.with_options(opt)\n            ds = ds.shuffle(2000)\n        ds = ds.map(self.parse_function, num_parallel_calls=AUTO)\n        if repeat:\n            ds = ds.repeat()\n        if augment:\n            ds = ds.map(self.augment_function, num_parallel_calls=AUTO)\n        ds = ds.batch(batch_size)\n        ds = ds.map(self.process_function, num_parallel_calls=AUTO)\n        ds = ds.prefetch(AUTO)\n        return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(name, input_shape, classes, output_bias=None):\n    \n    # Dictionary mapping name to model function\n    \n    EFFICIENT_NETS = {'B0': efn.EfficientNetB0, \n                      'B1': efn.EfficientNetB1, \n                      'B2': efn.EfficientNetB2, \n                      'B3': efn.EfficientNetB3, \n                      'B4': efn.EfficientNetB4, \n                      'B5': efn.EfficientNetB5, \n                      'B6': efn.EfficientNetB6,\n                      'B7': efn.EfficientNetB7}\n    \n    # Output layer bias initialization\n    \n    if output_bias is None:\n        output_bias = 'zeros'\n    else:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n        \n    \n    # Base model\n    \n    base_model = EFFICIENT_NETS[name](include_top=False, \n                                      weights='imagenet', \n                                      input_shape=input_shape)\n    \n    # Model\n    \n    inputs = tf.keras.Input(shape=input_shape)\n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(classes, bias_initializer=output_bias)(x)\n    outputs = tf.keras.layers.Activation('sigmoid', dtype='float32')(x) # Supports mixed-precision training\n    \n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n        \n    metrics = [\n        tf.keras.metrics.AUC(name='auc')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks(model_save_path, fold, verbose=1):\n    \n    verbose = int(verbose>0)\n    \n    if not os.path.exists(model_save_path):\n        os.makedirs(model_save_path)\n    \n    cpk_path = f'{model_save_path}/model-f{fold}.h5'\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=verbose\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_auc',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=10, \n        verbose=verbose\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]\n    \n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main Training Pipeline\n\n***Note: Running for 1 Fold only for experimental purpose***"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds_val_auc = [None] * FOLDS # Store the validation auc for each fold\n\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n\nprint(f'Training...')\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(np.arange(NUM_TF_RECS))):\n    \n    print(f'\\n\\n{\"*\"*100} \\nFOLD: {fold+1}')\n    \n    # Input Pipeline ******************************************************\n    \n    train_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in train_idx)\n    valid_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in valid_idx)\n    \n    ds = Dataset(IMG_SIZE)\n    \n    train_ds = ds.generator(train_files, \n                            BATCH_SIZE*REPLICAS, \n                            repeat=True, \n                            augment=True, \n                            shuffle=True)\n\n    valid_ds = ds.generator(valid_files, \n                            BATCH_SIZE*REPLICAS,  \n                            repeat=False, \n                            augment=False, \n                            shuffle=False)\n    \n    # Calculate the steps_per_epoch\n    \n    steps_per_epoch = count_items(train_files)//(BATCH_SIZE*REPLICAS) * 2\n    \n    \n    # Build Model ******************************************************\n    \n    tf.keras.backend.clear_session()\n        \n    with strategy.scope():\n        model = create_model(name=EFF_NET, \n                             input_shape=(IMG_SIZE,IMG_SIZE,3), \n                             classes=11)\n        model = compile_model(model, lr=0.0001)\n        \n    print(f'\\nModel initialized and compiled: EfficientNet-{EFF_NET}')\n    \n        \n    # Train ******************************************************\n   \n    callbacks = create_callbacks(MODEL_PATH, fold+1, verbose=VERBOSE)\n\n    print(f'\\nModel training...\\n')\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS, \n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_ds, \n                        callbacks=callbacks, \n                        verbose=VERBOSE)\n    \n    # Save acc for each fold in a list\n    folds_val_auc[fold] = max(history.history['val_auc'])\n    \n    print(f'\\nModel trained \\n\\nFOLD-{fold+1} Validation AUC = {folds_val_auc[fold]}')\n    \n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}